{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Klasifikasi Hewan.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imadegunawinangun/10-Animal-Classification/blob/main/Klasifikasi_Hewan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVXN9_TmOoVa"
      },
      "source": [
        "!git clone https://github.com/RumahGugun/10-Animal-Classification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBnlyYjNJKha"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import shutil\n",
        "import zipfile\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-Ot5CNKOvv8"
      },
      "source": [
        "ls 10-Animal-Classification/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEd32tuuRGpu"
      },
      "source": [
        "ls 10-Animal-Classification/raw-img/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck0SAkjxhLSl"
      },
      "source": [
        "base_dir = '10-Animal-Classification/raw-img'\n",
        "\n",
        "cane = os.path.join(base_dir, 'cane')\n",
        "elefante = os.path.join(base_dir, 'elefante')\n",
        "gallina = os.path.join(base_dir, 'gallina')\n",
        "mucca = os.path.join(base_dir, 'mucca')\n",
        "ragno = os.path.join(base_dir, 'ragno')\n",
        "cavallo = os.path.join(base_dir, 'cavallo')\n",
        "farfalla = os.path.join(base_dir, 'farfalla')\n",
        "gatto = os.path.join(base_dir, 'gatto')\n",
        "pecora = os.path.join(base_dir, 'pecora')\n",
        "scoiattolo = os.path.join(base_dir, 'scoiattolo')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KBcgAPxRG6W"
      },
      "source": [
        "import ntpath\n",
        "\n",
        "def path_leaf(path):\n",
        "  head, tail = ntpath.split(path)\n",
        "  return tail"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOP6arwiZvGA"
      },
      "source": [
        "def load_image(datadir):\n",
        "  image_path = []\n",
        "  label = []\n",
        "  path_temp = path_leaf(datadir)\n",
        "\n",
        "  for i in range(len(os.listdir(datadir))):\n",
        "    image_path.append(os.path.join(datadir, os.listdir(datadir)[i].strip()))\n",
        "    label.append(path_temp)\n",
        "\n",
        "  image_paths = np.asarray(image_path)\n",
        "  labels = np.asarray(label)\n",
        "  return image_paths, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYRksgYqZ0SO"
      },
      "source": [
        "cane_data, cane_label = load_image(cane)\n",
        "elefante_data, elefante_labels = load_image(elefante)\n",
        "gallina_data, gallina_labels = load_image(gallina)\n",
        "mucca_data, mucca_labels = load_image(mucca)\n",
        "ragno_data, ragno_labels = load_image(ragno)\n",
        "cavallo_data, cavallo_labels = load_image(cavallo)\n",
        "farfalla_data, farfalla_labels = load_image(farfalla)\n",
        "gatto_data, gatto_labels = load_image(gatto)\n",
        "pecora_data, pecora_labels = load_image(pecora)\n",
        "scoiattolo_data, scoiattolo_labels = load_image(scoiattolo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrW2omEWPpJ_"
      },
      "source": [
        "cane_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHf9tkEuPsl7"
      },
      "source": [
        "cane_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcdow7XpTZVU"
      },
      "source": [
        "#JALANKAN UNTUK MENGHAPUS FOLDER TRAINING DAN VALIDATION\n",
        "#shutil.rmtree(base_dir+'training')\n",
        "#shutil.rmtree(base_dir+'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA1vr_A_ndsm"
      },
      "source": [
        "if not os.path.exists(base_dir+'training'): os.makedirs(base_dir+'training')\n",
        "if not os.path.exists(base_dir+'training/cane'): os.makedirs(base_dir+'training/cane')\n",
        "#if not os.path.exists(base_dir+'training/elefante'): os.makedirs(base_dir+'training/elefante')\n",
        "if not os.path.exists(base_dir+'training/gallina'): os.makedirs(base_dir+'training/gallina')\n",
        "#if not os.path.exists(base_dir+'training/mucca'): os.makedirs(base_dir+'training/mucca')\n",
        "if not os.path.exists(base_dir+'training/ragno'): os.makedirs(base_dir+'training/ragno')\n",
        "#if not os.path.exists(base_dir+'training/cavallo'): os.makedirs(base_dir+'training/cavallo')\n",
        "#if not os.path.exists(base_dir+'training/farfalla'): os.makedirs(base_dir+'training/farfalla')\n",
        "#if not os.path.exists(base_dir+'training/gatto'): os.makedirs(base_dir+'training/gatto')\n",
        "#if not os.path.exists(base_dir+'training/pecora'): os.makedirs(base_dir+'training/pecora')\n",
        "#if not os.path.exists(base_dir+'training/scoiattolo'): os.makedirs(base_dir+'training/scoiattolo')\n",
        "\n",
        "if not os.path.exists(base_dir+'validation'):  os.makedirs(base_dir+'validation')\n",
        "if not os.path.exists(base_dir+'validation/cane'): os.makedirs(base_dir+'validation/cane')\n",
        "#if not os.path.exists(base_dir+'validation/elefante'): os.makedirs(base_dir+'validation/elefante')\n",
        "if not os.path.exists(base_dir+'validation/gallina'): os.makedirs(base_dir+'validation/gallina')\n",
        "#if not os.path.exists(base_dir+'validation/mucca'): os.makedirs(base_dir+'validation/mucca')\n",
        "if not os.path.exists(base_dir+'validation/ragno'): os.makedirs(base_dir+'validation/ragno')\n",
        "#if not os.path.exists(base_dir+'validation/cavallo'): os.makedirs(base_dir+'validation/cavallo')\n",
        "#if not os.path.exists(base_dir+'validation/farfalla'): os.makedirs(base_dir+'validation/farfalla')\n",
        "#if not os.path.exists(base_dir+'validation/gatto'): os.makedirs(base_dir+'validation/gatto')\n",
        "#if not os.path.exists(base_dir+'validation/pecora'): os.makedirs(base_dir+'validation/pecora')\n",
        "#if not os.path.exists(base_dir+'validation/scoiattolo'): os.makedirs(base_dir+'validation/scoiattolo')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kA9qNPoiN1di"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "cane_train, cane_valid = train_test_split(cane_data, train_size = 0.8, random_state = 1)\n",
        "print('cane Training Samples: {}\\nValid Samples: {}'.format(len(cane_train), len(cane_valid)))\n",
        "for i in range(len(cane_train)):\n",
        "  if not os.path.exists(base_dir+'training/cane/'+path_leaf(cane_train[i])):\n",
        "    shutil.copyfile(cane_train[i], base_dir+'training/cane/'+path_leaf(cane_train[i]))\n",
        "for i in range(len(cane_valid)):\n",
        "  if not os.path.exists(base_dir+'validation/cane/'+path_leaf(cane_valid[i])):\n",
        "    shutil.copyfile(cane_valid[i], base_dir+'validation/cane/'+path_leaf(cane_valid[i]))\n",
        "\n",
        "#elefante_train, elefante_valid = train_test_split(elefante_data, train_size = 0.8, random_state = 1)\n",
        "#print('elefante Training Samples: {}\\nValid Samples: {}'.format(len(elefante_train), len(elefante_valid)))\n",
        "#for i in range(len(elefante_train)):\n",
        "#  if not os.path.exists(base_dir+'training/elefante/'+path_leaf(elefante_train[i])):\n",
        "#    shutil.copyfile(elefante_train[i], base_dir+'training/elefante/'+path_leaf(elefante_train[i]))\n",
        "#for i in range(len(elefante_valid)):\n",
        "#  if not os.path.exists(base_dir+'validation/elefante/'+path_leaf(elefante_valid[i])):\n",
        "#    shutil.copyfile(elefante_valid[i], base_dir+'validation/elefante/'+path_leaf(elefante_valid[i]))\n",
        "\n",
        "gallina_train, gallina_valid = train_test_split(gallina_data, train_size = 0.8, random_state = 1)\n",
        "print('gallina Training Samples: {}\\nValid Samples: {}'.format(len(gallina_train), len(gallina_valid)))\n",
        "for i in range(len(gallina_train)):\n",
        "  shutil.copyfile(gallina_train[i], base_dir+'training/gallina/'+path_leaf(gallina_train[i]))\n",
        "for i in range(len(gallina_valid)):\n",
        "  shutil.copyfile(gallina_valid[i], base_dir+'validation/gallina/'+path_leaf(gallina_valid[i]))\n",
        "\n",
        "#mucca_train, mucca_valid = train_test_split(mucca_data, train_size = 0.8, random_state = 1)\n",
        "#print('mucca Training Samples: {}\\nValid Samples: {}'.format(len(mucca_train), len(mucca_valid)))\n",
        "#for i in range(len(mucca_train)):\n",
        "#  shutil.copyfile(mucca_train[i], base_dir+'training/mucca/'+path_leaf(mucca_train[i]))\n",
        "#for i in range(len(mucca_valid)):\n",
        "#  shutil.copyfile(mucca_valid[i], base_dir+'validation/mucca/'+path_leaf(mucca_valid[i]))\n",
        "\n",
        "ragno_train, ragno_valid = train_test_split(ragno_data, train_size = 0.8, random_state = 1)\n",
        "print('ragno Training Samples: {}\\nValid Samples: {}'.format(len(ragno_train), len(ragno_valid)))\n",
        "for i in range(len(ragno_train)):\n",
        "  shutil.copyfile(ragno_train[i], base_dir+'training/ragno/'+path_leaf(ragno_train[i]))\n",
        "for i in range(len(ragno_valid)):\n",
        "  shutil.copyfile(ragno_valid[i], base_dir+'validation/ragno/'+path_leaf(ragno_valid[i]))\n",
        "\n",
        "#cavallo_train, cavallo_valid = train_test_split(cavallo_data, train_size = 0.8, random_state = 1)\n",
        "#print('cavallo Training Samples: {}\\nValid Samples: {}'.format(len(cavallo_train), len(cavallo_valid)))\n",
        "#for i in range(len(cavallo_train)):\n",
        "#  shutil.copyfile(cavallo_train[i], base_dir+'training/cavallo/'+path_leaf(cavallo_train[i]))\n",
        "#for i in range(len(cavallo_valid)):\n",
        "#  shutil.copyfile(cavallo_valid[i], base_dir+'validation/cavallo/'+path_leaf(cavallo_valid[i]))\n",
        "\n",
        "#farfalla_train, farfalla_valid = train_test_split(farfalla_data, train_size = 0.8, random_state = 1)\n",
        "#print('farfalla Training Samples: {}\\nValid Samples: {}'.format(len(farfalla_train), len(farfalla_valid)))\n",
        "#for i in range(len(farfalla_train)):\n",
        "#  shutil.copyfile(farfalla_train[i], base_dir+'training/farfalla/'+path_leaf(farfalla_train[i]))\n",
        "#for i in range(len(farfalla_valid)):\n",
        "#  shutil.copyfile(farfalla_valid[i], base_dir+'validation/farfalla/'+path_leaf(farfalla_valid[i]))\n",
        "#  \n",
        "#gatto_train, gatto_valid = train_test_split(gatto_data, train_size = 0.8, random_state = 1)\n",
        "#print('gatto Training Samples: {}\\nValid Samples: {}'.format(len(gatto_train), len(gatto_valid)))\n",
        "#for i in range(len(gatto_train)):\n",
        "#  shutil.copyfile(gatto_train[i], base_dir+'training/gatto/'+path_leaf(gatto_train[i]))\n",
        "#for i in range(len(gatto_valid)):\n",
        "#  shutil.copyfile(gatto_valid[i], base_dir+'validation/gatto/'+path_leaf(gatto_valid[i]))\n",
        "#  \n",
        "#pecora_train, pecora_valid = train_test_split(pecora_data, train_size = 0.8, random_state = 1)\n",
        "#print('pecora Training Samples: {}\\nValid Samples: {}'.format(len(pecora_train), len(pecora_valid)))\n",
        "#for i in range(len(pecora_train)):\n",
        "#  shutil.copyfile(pecora_train[i], base_dir+'training/pecora/'+path_leaf(pecora_train[i]))\n",
        "#for i in range(len(pecora_valid)):\n",
        "#  shutil.copyfile(pecora_valid[i], base_dir+'validation/pecora/'+path_leaf(pecora_valid[i]))\n",
        "#  \n",
        "#scoiattolo_train, scoiattolo_valid = train_test_split(scoiattolo_data, train_size = 0.8, random_state = 1)\n",
        "#print('scoiattolo Training Samples: {}\\nValid Samples: {}'.format(len(scoiattolo_train), len(scoiattolo_valid)))\n",
        "#for i in range(len(scoiattolo_train)):\n",
        "#  shutil.copyfile(scoiattolo_train[i], base_dir+'training/scoiattolo/'+path_leaf(scoiattolo_train[i]))\n",
        "#for i in range(len(scoiattolo_valid)):\n",
        "#  shutil.copyfile(scoiattolo_valid[i], base_dir+'validation/scoiattolo/'+path_leaf(scoiattolo_valid[i]))\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42REKaouaDjO"
      },
      "source": [
        "train_generator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    rotation_range=90,\n",
        "    height_shift_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    brightness_range = (0.3,1.2),\n",
        ")\n",
        "\n",
        "valid_generator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIO0hMKbaHxi"
      },
      "source": [
        "IMAGE_WIDTH=224\n",
        "IMAGE_HEIGHT=224\n",
        "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "IMAGE_CHANNELS=3\n",
        "IMAGE_SHAPE = (IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)\n",
        "EPOCHS = 200\n",
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE = 3e-4\n",
        "\n",
        "train_images = train_generator.flow_from_directory(\n",
        "    base_dir+'training',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "val_images = valid_generator.flow_from_directory(\n",
        "    base_dir+'validation',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTHAVwcIjOB0"
      },
      "source": [
        "for _ in range(5):\n",
        "    img, label = train_images.next()\n",
        "    print(img.shape)   #  (1,256,256,3)\n",
        "    plt.imshow(img[1])\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPthugU3HRx6"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    # This is the first convolution\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu', input_shape=IMAGE_SHAPE),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "  \n",
        "\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=LEARNING_RATE),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzBb3LimzVnb"
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.92 and logs.get('val_accuracy')>0.92):\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks90 = myCallback()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-Bupd4WuyU2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "outputId": "5a95cd14-95f6-44fd-cdef-5d4ace1ef0ae"
      },
      "source": [
        "history = model.fit(\n",
        "    train_images,\n",
        "    validation_data=val_images,\n",
        "    epochs=100,\n",
        "    \n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_accuracy',\n",
        "            patience=20,\n",
        "            restore_best_weights=True\n",
        "        ),\n",
        "        callbacks90\n",
        "    ],\n",
        ")\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "320/320 [==============================] - 167s 520ms/step - loss: 1.0713 - accuracy: 0.4065 - val_loss: 0.9401 - val_accuracy: 0.5907\n",
            "Epoch 2/100\n",
            "320/320 [==============================] - 166s 518ms/step - loss: 0.9634 - accuracy: 0.5392 - val_loss: 0.8368 - val_accuracy: 0.6286\n",
            "Epoch 3/100\n",
            "320/320 [==============================] - 166s 519ms/step - loss: 0.8827 - accuracy: 0.6019 - val_loss: 0.7162 - val_accuracy: 0.6888\n",
            "Epoch 4/100\n",
            "320/320 [==============================] - 167s 523ms/step - loss: 0.8158 - accuracy: 0.6400 - val_loss: 0.7692 - val_accuracy: 0.6787\n",
            "Epoch 5/100\n",
            "320/320 [==============================] - 167s 520ms/step - loss: 0.7596 - accuracy: 0.6748 - val_loss: 0.6423 - val_accuracy: 0.7244\n",
            "Epoch 6/100\n",
            "320/320 [==============================] - 166s 519ms/step - loss: 0.7282 - accuracy: 0.6991 - val_loss: 0.6557 - val_accuracy: 0.6962\n",
            "Epoch 7/100\n",
            "320/320 [==============================] - 167s 521ms/step - loss: 0.6759 - accuracy: 0.7229 - val_loss: 0.5720 - val_accuracy: 0.7744\n",
            "Epoch 8/100\n",
            "320/320 [==============================] - 170s 531ms/step - loss: 0.6371 - accuracy: 0.7498 - val_loss: 0.5180 - val_accuracy: 0.7850\n",
            "Epoch 9/100\n",
            "320/320 [==============================] - 170s 532ms/step - loss: 0.6044 - accuracy: 0.7656 - val_loss: 0.5352 - val_accuracy: 0.7838\n",
            "Epoch 10/100\n",
            "320/320 [==============================] - 175s 548ms/step - loss: 0.5805 - accuracy: 0.7782 - val_loss: 0.4294 - val_accuracy: 0.8436\n",
            "Epoch 11/100\n",
            "320/320 [==============================] - 176s 551ms/step - loss: 0.5502 - accuracy: 0.7975 - val_loss: 0.6297 - val_accuracy: 0.7346\n",
            "Epoch 12/100\n",
            "320/320 [==============================] - 174s 542ms/step - loss: 0.5344 - accuracy: 0.8042 - val_loss: 0.3798 - val_accuracy: 0.8514\n",
            "Epoch 13/100\n",
            "320/320 [==============================] - 167s 522ms/step - loss: 0.5238 - accuracy: 0.8083 - val_loss: 0.4721 - val_accuracy: 0.8030\n",
            "Epoch 14/100\n",
            "320/320 [==============================] - 167s 523ms/step - loss: 0.5032 - accuracy: 0.8177 - val_loss: 0.6150 - val_accuracy: 0.7373\n",
            "Epoch 15/100\n",
            "221/320 [===================>..........] - ETA: 50s - loss: 0.4985 - accuracy: 0.8153"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-e88594b7c41c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         ),\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mcallbacks90\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     ],\n\u001b[1;32m     14\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1187\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \"\"\"\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    313\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    510\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \"\"\"\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2LFqXP31G5o"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Accuracy')\n",
        "plt.ylabel('acc')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFaf7Mwn1xTv"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KFgDJd0wACJ"
      },
      "source": [
        "# Convert the model.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open('model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGAqLM9dycl2"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BrZL-mp9a9k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}